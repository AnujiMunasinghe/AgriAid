{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import json\n",
    "import numpy as np\n",
    "from flask import Flask, request, Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def Predict():\n",
    "\n",
    "    print(\"start\")\n",
    "    input_data = request.get_json()\n",
    "\n",
    "    # Preprocess the data\n",
    "    crop_encoder = LabelEncoder()\n",
    "    region_encoder = LabelEncoder()\n",
    "    quarter_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the encoders with the available data\n",
    "    crop_encoder.fit(['Capsicum', 'Green Chilli'])\n",
    "    # Update with the classes used for training the model\n",
    "    region_encoder.fit(['Colombo', 'Ampara',\n",
    "                        'Anuradhapura', 'Badulla', 'Batticaloa', 'Galle', 'Gampaha', 'Hambantota', 'Jaffna', 'Kalutara', 'Kandy', 'Kegalle', 'Kilinochchi', 'Kurunegala', 'Mannar', 'Matala', 'Monaragala', 'Mullaitivu', 'Nuwara Eliya', 'Polonnaruwa', 'Puttalam', 'Ratnapura', 'Trincomalee', 'Vavuniya'])\n",
    "\n",
    "    # Update with the classes used for training the model\n",
    "    quarter_encoder.fit(['Q1', 'Q2', 'Q3'])\n",
    "\n",
    "    # Encode the input values\n",
    "    input_crop_encoded = crop_encoder.transform([input_data['Crop']])[0]\n",
    "    input_region_encoded = region_encoder.transform([input_data['Region']])[0]\n",
    "    input_quarter_encoded = quarter_encoder.transform(\n",
    "        [input_data['Quarter']])[0]\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('trained_model.h5')\n",
    "\n",
    "    # Preprocess the input data\n",
    "    scaler = MinMaxScaler()\n",
    "    input_data_scaled = scaler.fit_transform(\n",
    "        [[input_crop_encoded, input_region_encoded, input_quarter_encoded]])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(input_data_scaled)\n",
    "\n",
    "    # Fit the scaler with the training data\n",
    "    scaler_output = MinMaxScaler()\n",
    "    # Assuming the target variable was scaled between 0 and 1 during training\n",
    "    scaler_output.fit([[0], [1]])\n",
    "\n",
    "    # Decode the predictions\n",
    "    demand_pred = scaler_output.inverse_transform(\n",
    "        predictions.reshape(-1, 1)).flatten()\n",
    "    supply_pred = scaler_output.inverse_transform(\n",
    "        predictions.reshape(-1, 1)).flatten()\n",
    "    price_pred = scaler_output.inverse_transform(\n",
    "        predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Print the predictions\n",
    "    print(\"Demand Prediction:\", demand_pred[0])\n",
    "    print(\"Supply Prediction:\", supply_pred[1])\n",
    "    print(\"Price Prediction:\", price_pred[2])\n",
    "\n",
    "    result = json.dumps({\n",
    "        \"Demand\": str(demand_pred[0]),\n",
    "        \"Supply\": str(supply_pred[1]),\n",
    "        \"Price\": str(price_pred[2])})\n",
    "\n",
    "    return Response(response=result, status=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello, world!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
